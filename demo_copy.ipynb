{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Evgenia1917/Final-Practice/blob/main/demo_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_WzkMB2W9D3"
      },
      "source": [
        "Устанавливаем transformers из репозитория, а также зависимости:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ5QvLo0WvcC",
        "outputId": "5d4fda8a-0a98-449f-b6a7-296f69020960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 78284, done.\u001b[K\n",
            "remote: Counting objects: 100% (1325/1325), done.\u001b[K\n",
            "remote: Compressing objects: 100% (811/811), done.\u001b[K\n",
            "remote: Total 78284 (delta 796), reused 916 (delta 460), pack-reused 76959\u001b[K\n",
            "Receiving objects: 100% (78284/78284), 61.16 MiB | 23.50 MiB/s, done.\n",
            "Resolving deltas: 100% (55754/55754), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSAFeQ57W1Td",
        "outputId": "ab677912-464c-4d0d-e972-2d7902c44c71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/transformers/\n",
        "!pip install . -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 5.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 30.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 32.5MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09aAj8ozW2U2",
        "outputId": "11d041b8-80d1-40cb-ee59-230e3f995ef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -r /content/transformers/examples/pytorch/translation/requirements.txt -q"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 266kB 3.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 33.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 31.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 41.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9MB 27.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 37.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 27.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 42.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNSdWHxiXFdv"
      },
      "source": [
        "Переходим в папку с склонированным репо:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5E94x5IW3-H",
        "outputId": "fadf8a91-decf-4114-eb31-6c2d7b573ad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/transformers/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdnJH5huXE3z"
      },
      "source": [
        "Запускаем обучающий скрипт:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4b--uQvW6mM",
        "outputId": "d498b58c-d9bf-44ef-b722-1d29cb3ad17c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "!python examples/pytorch/translation/run_translation.py \\\n",
        "    --model_name_or_path \"Helsinki-NLP/opus-mt-en-ru\" \\ #путь к модели — собственной или предобученной. в примере используется модель MarianMT для перевода с английского на русский\n",
        "    --do_train \\ #задачи. do_train – обучение, do_eval – оценка, do_predict — предсказывание на тестовой выборке\n",
        "    --source_lang en \\ # исходный и целевой языки\n",
        "    --target_lang ru \\\n",
        "    --num_train_epochs 10 \\ # количество эпох обучения. дефолтное — 3\n",
        "    --max_source_length 512 \\ # максимальная длина текста в исходном, целевом и валидационном датасетах\n",
        "    --max_target_length 512 \\\n",
        "    --val_max_target_length 512 \\\n",
        "    --train_file  '' \\ # прописать: путь к обучающему файлу. нужно загрузить на гугл-диск и подключить гугл-диск к блокноту\n",
        "    --validation_file '' \\ # прописать: путь к валидационному файлу\n",
        "    --output_dir '' \\  # прописать: папка сохранения \n",
        "    --per_device_train_batch_size=4 \\ # размер батча на обучении/валидации\n",
        "    --per_device_eval_batch_size=4 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --pad_to_max_length False \\ # добивать ли нулями до максимальной длины текста\n",
        "    --predict_with_generate"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-2f6f1b7f05ff>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    --do_train \\ #задачи. do_train – обучение, do_eval – оценка, do_predict — предсказывание на тестовой выборке\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClSn4zL7YZ9R"
      },
      "source": [
        "from transformers import pipeline, AutoTokenizer,AutoModelForSeq2SeqLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckoA_cCzYaop"
      },
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained('') # пути к нашей модели и токенайзеру\n",
        "tokenizer = AutoTokenizer.from_pretrained('')\n",
        "text = '' # текст для перевода\n",
        "translator = pipeline(\"translation_en_to_ru\", model, tokenizer) # инициализация переводчика\n",
        "translator[0]['translation_text'] "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}