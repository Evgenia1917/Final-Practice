{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AY81wrdM8hS"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import zipfile\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxsECFFhM-dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240ab96c-844f-4265-9b7f-5baa85bbd4d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgOMT0MRQec_",
        "outputId": "c25e04f8-ca9b-4005-9888-6c93e848d6e3"
      },
      "source": [
        "zip_file = \"/content/drive/MyDrive/data/xdzlyx.com.zip\"\n",
        "z = zipfile.ZipFile(zip_file, \"r\")\n",
        "z.extractall()\n",
        "print(os.listdir())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'zh', 'en', 'drive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_GUdpFVNTu_"
      },
      "source": [
        "values_zh = []\n",
        "\n",
        "for file in sorted(glob.glob(\"/content/zh/*.txt\")):\n",
        "  with open(file, 'r', encoding = 'utf8') as f:\n",
        "    data = f.read()\n",
        "  values_zh.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8KVcqj43qGY"
      },
      "source": [
        "values_en = []\n",
        "\n",
        "for file in sorted(glob.glob(\"/content/en/*.txt\")):\n",
        "  with open(file, 'r', encoding = 'utf8') as f:\n",
        "    data = f.read()\n",
        "  values_en.append(data)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "req5Y1QT_OlF"
      },
      "source": [
        "metrics_en = values_en[:100]\n",
        "metrics_zh = values_zh[:100]\n",
        "metrics = [{\"translation\": {\"en\":x, \"zh\":y}} for x, y in zip(metrics_en, metrics_zh)]\n",
        "with jsonlines.open('metrics.jsonl', mode='w') as writer:\n",
        "    writer.write_all(metrics)\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAnekyKi3wlu"
      },
      "source": [
        "!pip install jsonlines\n",
        "import jsonlines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rT2Er6_VNzZ",
        "outputId": "bd5f4020-9f5d-4306-e8aa-6344c4288f94"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czg9hHnzVRXA",
        "outputId": "77bb2bff-9d86-4e8c-d2a4-5540e3d82265"
      },
      "source": [
        "%cd /content/transformers/\n",
        "!pip install . -q"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 636 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 10.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.1 MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SngRUAXCVYvd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dae8363-645a-496e-a788-e63aa2f221a4"
      },
      "source": [
        "!pip install -r /content/transformers/examples/pytorch/translation/requirements.txt -q"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██████▋                         | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 20 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 30 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 49 kB 3.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 264 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 20.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 24.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 357 kB 23.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 26.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 50.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 121 kB 50.4 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE_5H9YeVcuH",
        "outputId": "f46ac4ac-dadc-42ed-9b8c-b12a2743cb71"
      },
      "source": [
        "%cd /content/transformers/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9WMYwho4iRW",
        "outputId": "c3386220-d168-40b8-acd1-4524a1331445"
      },
      "source": [
        "!python examples/pytorch/translation/run_translation.py \\\n",
        "--model_name_or_path '/content/drive/MyDrive/Output/--per_device_train_batch_size=4/' \\\n",
        "--do_predict True \\\n",
        "--source_lang en \\\n",
        "--target_lang zh \\\n",
        "--max_source_length 512 \\\n",
        "--max_target_length 512 \\\n",
        "--train_file  '/content/drive/MyDrive/data/data_small_batches/train1.json' \\\n",
        "--test_file '/content/drive/MyDrive/data/data_small_batches/metrics_100.json' \\\n",
        "--output_dir '/content/drive/MyDrive/Metrics/output/'"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-09 07:58:21.977939: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "08/09/2021 07:58:23 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False\n",
            "08/09/2021 07:58:23 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=0,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/MyDrive/Metrics/output/runs/Aug09_07-58-23_04c874073ffc,\n",
            "logging_first_step=False,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=/content/drive/MyDrive/Metrics/output/,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "predict_with_generate=False,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=output,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=None,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=/content/drive/MyDrive/Metrics/output/,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "08/09/2021 07:58:24 - WARNING - datasets.builder - Using custom data configuration default-4b681d9f75b53ce8\n",
            "08/09/2021 07:58:24 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-4b681d9f75b53ce8/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264)\n",
            "Downloading and preparing dataset json/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/json/default-4b681d9f75b53ce8/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264...\n",
            "100% 2/2 [00:00<00:00, 6163.56it/s]\n",
            "08/09/2021 07:58:24 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
            "08/09/2021 07:58:24 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
            "100% 2/2 [00:00<00:00, 94.26it/s]\n",
            "08/09/2021 07:58:24 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "08/09/2021 07:58:24 - INFO - datasets.builder - Generating split train\n",
            "08/09/2021 07:58:24 - INFO - datasets.builder - Generating split test\n",
            "08/09/2021 07:58:24 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-4b681d9f75b53ce8/0.0.0/45636811569ec4a6630521c18235dfbbab83b7ab572e3393c5ba68ccabe98264. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 555.32it/s]\n",
            "[INFO|configuration_utils.py:543] 2021-08-09 07:58:24,729 >> loading configuration file /content/drive/MyDrive/Output/--per_device_train_batch_size=4/config.json\n",
            "[INFO|configuration_utils.py:581] 2021-08-09 07:58:24,731 >> Model config MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-zh\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      65000\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 65000,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"extra_pos_embeddings\": 0,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 65000,\n",
            "  \"scale_embedding\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.10.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 65001\n",
            "}\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"examples/pytorch/translation/run_translation.py\", line 617, in <module>\n",
            "    main()\n",
            "  File \"examples/pytorch/translation/run_translation.py\", line 338, in main\n",
            "    use_auth_token=True if model_args.use_auth_token else None,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\", line 413, in from_pretrained\n",
            "    tokenizer_class = tokenizer_class_from_name(tokenizer_class_candidate)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\", line 208, in tokenizer_class_from_name\n",
            "    return getattr(module, class_name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/file_utils.py\", line 1988, in __getattr__\n",
            "    raise AttributeError(f\"module {self.__name__} has no attribute {name}\")\n",
            "AttributeError: module transformers.models.mbart50 has no attribute MarianTokenizerFast\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5NZiYJ9oLJK"
      },
      "source": [
        "from transformers import pipeline, AutoTokenizer,AutoModelForSeq2SeqLM"
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}
