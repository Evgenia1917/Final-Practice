{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Evgenia1917/Final-Practice/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_WzkMB2W9D3"
      },
      "source": [
        "Устанавливаем transformers из репозитория, а также зависимости:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ5QvLo0WvcC"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSAFeQ57W1Td"
      },
      "source": [
        "%cd /content/transformers/\n",
        "!pip install . -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09aAj8ozW2U2"
      },
      "source": [
        "!pip install -r /content/transformers/examples/pytorch/translation/requirements.txt -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNSdWHxiXFdv"
      },
      "source": [
        "Переходим в папку с склонированным репо:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5E94x5IW3-H"
      },
      "source": [
        "%cd /content/transformers/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdnJH5huXE3z"
      },
      "source": [
        "Запускаем обучающий скрипт:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4b--uQvW6mM"
      },
      "source": [
        "!python examples/pytorch/translation/run_translation.py \\\n",
        "    --model_name_or_path \"Helsinki-NLP/opus-mt-en-ru\" \\ #путь к модели — собственной или предобученной. в примере используется модель MarianMT для перевода с английского на русский\n",
        "    --do_train \\ #задачи. do_train – обучение, do_eval – оценка, do_predict — предсказывание на тестовой выборке\n",
        "    --source_lang en \\ # исходный и целевой языки\n",
        "    --target_lang ru \\\n",
        "    --num_train_epochs 10 \\ # количество эпох обучения. дефолтное — 3\n",
        "    --max_source_length 512 \\ # максимальная длина текста в исходном, целевом и валидационном датасетах\n",
        "    --max_target_length 512 \\\n",
        "    --val_max_target_length 512 \\\n",
        "    --train_file  '' \\ # прописать: путь к обучающему файлу. нужно загрузить на гугл-диск и подключить гугл-диск к блокноту\n",
        "    --validation_file '' \\ # прописать: путь к валидационному файлу\n",
        "    --output_dir '' \\  # прописать: папка сохранения \n",
        "    --per_device_train_batch_size=4 \\ # размер батча на обучении/валидации\n",
        "    --per_device_eval_batch_size=4 \\\n",
        "    --overwrite_output_dir \\\n",
        "    --pad_to_max_length False \\ # добивать ли нулями до максимальной длины текста\n",
        "    --predict_with_generate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClSn4zL7YZ9R"
      },
      "source": [
        "from transformers import pipeline, AutoTokenizer,AutoModelForSeq2SeqLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckoA_cCzYaop"
      },
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained('') # пути к нашей модели и токенайзеру\n",
        "tokenizer = AutoTokenizer.from_pretrained('')\n",
        "text = '' # текст для перевода\n",
        "translator = pipeline(\"translation_en_to_ru\", model, tokenizer) # инициализация переводчика\n",
        "translator[0]['translation_text'] "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}